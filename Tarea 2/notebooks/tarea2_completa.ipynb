{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 2: Conteo Aproximado con MCMC\n",
    "## Aplicado a los modelos Hard-Core y q-coloraciones\n",
    "\n",
    "**Curso:** Cadenas de Markov y Aplicaciones (2025-II)  \n",
    "**Profesor:** Freddy Hernández-Romero  \n",
    "\n",
    "**Integrantes del grupo:**\n",
    "- Sergio Andrés Díaz Vera (seadiazve@unal.edu.co)\n",
    "- Julián Mateo Espinosa Ospina (juespinosao@unal.edu.co)\n",
    "\n",
    "**Fecha de entrega:** Noviembre 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "En esta tarea implementamos algoritmos de conteo aproximado basados en Cadenas de Markov Monte Carlo (MCMC) para dos problemas fundamentales en teoría de grafos:\n",
    "\n",
    "1. **q-Coloraciones**: Asignaciones de q colores a los vértices de un grafo tal que vértices adyacentes tienen colores diferentes.\n",
    "2. **Modelo Hard-Core**: Configuraciones donde ningún par de vértices adyacentes están simultáneamente ocupados.\n",
    "\n",
    "Basamos nuestra implementación en el **Teorema 9.1**, que establece la existencia de un esquema de aproximación polinomial aleatorizado para estos problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "# Importaciones necesarias\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Agregar el directorio padre al path\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from typing import List, Dict, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "%matplotlib inline\n",
    "\n",
    "# Importar implementación mejorada desde src\n",
    "from src.mcmc_counting import (\n",
    "    LatticeGraph, \n",
    "    QColoringApproximation, \n",
    "    HardCoreApproximation,\n",
    "    exact_chromatic_polynomial,\n",
    "    exact_hardcore_count,\n",
    "    run_q_coloring_experiment,\n",
    "    run_hardcore_experiment\n",
    ")\n",
    "\n",
    "print(\"Librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Aproximación del Número de q-Coloraciones\n",
    "\n",
    "### 1.a) Implementación basada en el Teorema 9.1\n",
    "\n",
    "El Teorema 9.1 establece que para grafos con grado máximo $d$ y $q > 2d^*$, existe un esquema de aproximación con:\n",
    "\n",
    "- **Número de simulaciones**: $\\frac{48d^2k^3}{\\varepsilon^2}$\n",
    "- **Pasos del Gibbs Sampler**: $k\\left(\\frac{2\\log(k)+\\log(\\varepsilon^{-1})+\\log(8)}{\\log\\frac{q}{q-1}} + 1\\right)$\n",
    "\n",
    "donde $k$ es el número de vértices y $\\varepsilon$ es la precisión deseada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración de experimentos:\n",
      "  • Tamaños de lattice K: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "  • Número de colores q: [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "  • Valores de epsilon: [0.5, 0.2, 0.1]\n"
     ]
    }
   ],
   "source": [
    "# Parámetros del experimento según el documento\n",
    "K_range = range(3, 21)  # 3 ≤ K ≤ 20\n",
    "q_range = range(2, 16)  # 2 ≤ q ≤ 15\n",
    "epsilon_values = [0.5, 0.2, 0.1]  # Valores de precisión\n",
    "\n",
    "print(\"Configuración de experimentos:\")\n",
    "print(f\"  • Tamaños de lattice K: {list(K_range)}\")\n",
    "print(f\"  • Número de colores q: {list(q_range)}\")\n",
    "print(f\"  • Valores de epsilon: {epsilon_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experimentos de muestra ===\n",
      "\n",
      "Ejecutando: K=3, q=9, ε=0.1\n",
      "\n",
      "=== Conteo Aproximado de q-Coloraciones ===\n",
      "Lattice: 3 × 3\n",
      "q = 9, d = 4, k = 9\n",
      "ε = 0.1\n",
      "Simulaciones por factor: 1000\n",
      "Tiempo de mezcla: 680\n",
      "Burn-in: 100\n",
      "  Progreso: 1000/5000 muestras\n",
      "  Progreso: 2000/5000 muestras\n",
      "  Progreso: 3000/5000 muestras\n",
      "  Progreso: 4000/5000 muestras\n",
      "  Progreso: 5000/5000 muestras\n",
      "\n",
      "✓ Completado en 32.29 segundos\n",
      "Estimación: 1.95e+06\n",
      "\n",
      "Ejecutando: K=4, q=9, ε=0.2\n",
      "\n",
      "=== Conteo Aproximado de q-Coloraciones ===\n",
      "Lattice: 4 × 4\n",
      "q = 9, d = 4, k = 16\n",
      "ε = 0.2\n",
      "Simulaciones por factor: 1000\n",
      "Tiempo de mezcla: 1271\n",
      "Burn-in: 127\n",
      "  Progreso: 1000/5000 muestras\n",
      "  Progreso: 2000/5000 muestras\n",
      "  Progreso: 3000/5000 muestras\n",
      "  Progreso: 4000/5000 muestras\n",
      "  Progreso: 5000/5000 muestras\n",
      "\n",
      "✓ Completado en 57.06 segundos\n",
      "Estimación: 1.53e+11\n",
      "\n",
      "Ejecutando: K=5, q=10, ε=0.1\n",
      "\n",
      "=== Conteo Aproximado de q-Coloraciones ===\n",
      "Lattice: 5 × 5\n",
      "q = 10, d = 4, k = 25\n",
      "ε = 0.1\n",
      "Simulaciones por factor: 1000\n",
      "Tiempo de mezcla: 2593\n",
      "Burn-in: 259\n",
      "  Progreso: 1000/5000 muestras\n",
      "  Progreso: 2000/5000 muestras\n",
      "  Progreso: 3000/5000 muestras\n",
      "  Progreso: 4000/5000 muestras\n",
      "  Progreso: 5000/5000 muestras\n",
      "\n",
      "✓ Completado en 116.08 segundos\n",
      "Estimación: 2.84e+19\n"
     ]
    }
   ],
   "source": [
    "# Experimentos de muestra\n",
    "print(\"\\n=== Experimentos de muestra ===\")\n",
    "sample_results = []\n",
    "\n",
    "# Casos representativos\n",
    "sample_cases = [\n",
    "    (3, 9, 0.1),\n",
    "    (4, 9, 0.2),\n",
    "    (5, 10, 0.1),\n",
    "]\n",
    "\n",
    "for K, q, eps in sample_cases:\n",
    "    print(f\"\\nEjecutando: K={K}, q={q}, ε={eps}\")\n",
    "    result = run_q_coloring_experiment(K, q, eps, verbose=True)\n",
    "    sample_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ejecutando experimentos completos ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experimentos q-coloraciones:  24%|██▎       | 17/72 [12:36<53:46, 58.66s/it]"
     ]
    }
   ],
   "source": [
    "# Ejecutar experimentos sistemáticos\n",
    "print(\"\\n=== Ejecutando experimentos completos ===\")\n",
    "\n",
    "all_results_q = []\n",
    "K_subset = [3, 4, 5, 6, 8, 10]\n",
    "q_subset = [9, 10, 12, 15]\n",
    "\n",
    "total = len(K_subset) * len(q_subset) * len(epsilon_values)\n",
    "with tqdm(total=total, desc=\"Experimentos q-coloraciones\") as pbar:\n",
    "    for K in K_subset:\n",
    "        for q in q_subset:\n",
    "            for eps in epsilon_values:\n",
    "                result = run_q_coloring_experiment(K, q, eps)\n",
    "                if result['valid']:\n",
    "                    all_results_q.append(result)\n",
    "                pbar.update(1)\n",
    "\n",
    "df_q = pd.DataFrame(all_results_q)\n",
    "print(f\"\\n{len(all_results_q)} experimentos válidos completados\")\n",
    "\n",
    "# Mostrar estadísticas\n",
    "print(\"\\n=== Resumen de parámetros utilizados ===\")\n",
    "for eps in epsilon_values:\n",
    "    df_eps = df_q[df_q['epsilon'] == eps]\n",
    "    if not df_eps.empty:\n",
    "        print(f\"\\nε = {eps}:\")\n",
    "        print(f\"  • Simulaciones promedio: {df_eps['num_simulations'].mean():.0f}\")\n",
    "        print(f\"  • Tiempo de mezcla promedio: {df_eps['mixing_time'].mean():.0f} pasos\")\n",
    "        print(f\"  • Tiempo ejecución promedio: {df_eps['elapsed_time'].mean():.2f} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de Resultados para q-Coloraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear visualizaciones\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Estimaciones vs tamaño del lattice para diferentes q\n",
    "ax1 = axes[0, 0]\n",
    "for q in df_q['q'].unique():\n",
    "    df_q_filtered = df_q[(df_q['q'] == q) & (df_q['epsilon'] == 0.1)]\n",
    "    if not df_q_filtered.empty:\n",
    "        ax1.semilogy(df_q_filtered['K'], df_q_filtered['estimate'], \n",
    "                    'o-', label=f'q={q}', markersize=8)\n",
    "ax1.set_xlabel('Tamaño del Lattice (K)')\n",
    "ax1.set_ylabel('log(Número de q-coloraciones)')\n",
    "ax1.set_title('Crecimiento del Número de q-Coloraciones')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Impacto de epsilon en el tiempo de ejecución\n",
    "ax2 = axes[0, 1]\n",
    "for eps in epsilon_values:\n",
    "    df_eps = df_q[(df_q['epsilon'] == eps) & (df_q['q'] == 10)]\n",
    "    if not df_eps.empty:\n",
    "        ax2.plot(df_eps['K'], df_eps['elapsed_time'], \n",
    "                'o-', label=f'ε={eps}', markersize=8)\n",
    "ax2.set_xlabel('Tamaño del Lattice (K)')\n",
    "ax2.set_ylabel('Tiempo de Ejecución (segundos)')\n",
    "ax2.set_title('Impacto de ε en el Tiempo de Cómputo (q=10)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Número de simulaciones requeridas\n",
    "ax3 = axes[1, 0]\n",
    "df_01 = df_q[df_q['epsilon'] == 0.1]\n",
    "if not df_01.empty:\n",
    "    pivot_sim = df_01.pivot_table(values='num_simulations', \n",
    "                                  index='K', columns='q', aggfunc='mean')\n",
    "    sns.heatmap(pivot_sim, annot=True, fmt='.0f', cmap='YlOrRd', ax=ax3)\n",
    "    ax3.set_title('Número de Simulaciones Requeridas (ε=0.1)')\n",
    "    ax3.set_xlabel('q (número de colores)')\n",
    "    ax3.set_ylabel('K (tamaño del lattice)')\n",
    "\n",
    "# 4. Tiempo de mezcla\n",
    "ax4 = axes[1, 1]\n",
    "if not df_01.empty:\n",
    "    pivot_mix = df_01.pivot_table(values='mixing_time', \n",
    "                                  index='K', columns='q', aggfunc='mean')\n",
    "    sns.heatmap(pivot_mix, annot=True, fmt='.0f', cmap='Blues', ax=ax4)\n",
    "    ax4.set_title('Tiempo de Mezcla del Gibbs Sampler (ε=0.1)')\n",
    "    ax4.set_xlabel('q (número de colores)')\n",
    "    ax4.set_ylabel('K (tamaño del lattice)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../resultados/q_coloraciones_analisis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Gráficas guardadas en resultados/q_coloraciones_analisis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b) Comparación con Conteo Exacto\n",
    "\n",
    "Para lattices pequeños, comparamos nuestras aproximaciones con el conteo exacto usando el polinomio cromático."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Comparación con Conteo Exacto ===\")\n",
    "print(\"\\nComparando aproximaciones con valores exactos para lattices pequeños:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'K':^5} {'q':^5} {'Exacto':^15} {'Aproximado':^15} {'Error (%)':^15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "comparison_results = []\n",
    "comparison_cases = [\n",
    "    (2, 5),\n",
    "    (2, 7),\n",
    "    (3, 9),\n",
    "    (3, 10),\n",
    "]\n",
    "\n",
    "for K, q in comparison_cases:\n",
    "    try:\n",
    "        exact = exact_chromatic_polynomial(K, q)\n",
    "        \n",
    "        lattice = LatticeGraph(K)\n",
    "        approx_obj = QColoringApproximation(lattice, q, epsilon=0.05)\n",
    "        estimate, _ = approx_obj.approximate_count(verbose=False)\n",
    "        \n",
    "        error = abs(estimate - exact) / exact * 100 if exact > 0 else 0\n",
    "        \n",
    "        print(f\"{K:^5} {q:^5} {exact:^15,} {estimate:^15.0f} {error:^15.2f}\")\n",
    "        \n",
    "        comparison_results.append({\n",
    "            'K': K,\n",
    "            'q': q,\n",
    "            'exact': exact,\n",
    "            'approximate': estimate,\n",
    "            'error_percent': error\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"{K:^5} {q:^5} {'N/A':^15} {'N/A':^15} {'N/A':^15}\")\n",
    "\n",
    "print(\"-\" * 70)\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_results)\n",
    "if not df_comparison.empty:\n",
    "    print(f\"\\nError promedio: {df_comparison['error_percent'].mean():.2f}%\")\n",
    "    print(f\"Error máximo: {df_comparison['error_percent'].max():.2f}%\")\n",
    "    print(f\"Error mínimo: {df_comparison['error_percent'].min():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Aproximación del Número de Configuraciones del Modelo Hard-Core\n",
    "\n",
    "El modelo Hard-Core representa configuraciones donde ningún par de vértices adyacentes pueden estar ocupados simultáneamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimentos de muestra para Hard-Core\n",
    "print(\"\\n=== Experimentos Hard-Core de muestra ===\")\n",
    "\n",
    "hc_sample_cases = [\n",
    "    (3, 0.1),\n",
    "    (4, 0.2),\n",
    "    (5, 0.1),\n",
    "]\n",
    "\n",
    "hc_sample_results = []\n",
    "for K, eps in hc_sample_cases:\n",
    "    print(f\"\\nEjecutando Hard-Core: K={K}, ε={eps}\")\n",
    "    result = run_hardcore_experiment(K, eps, verbose=True)\n",
    "    hc_sample_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar experimentos sistemáticos para Hard-Core\n",
    "print(\"\\n=== Ejecutando experimentos Hard-Core completos ===\")\n",
    "\n",
    "all_results_hc = []\n",
    "K_range_hc = [3, 4, 5, 6, 8, 10, 12, 15]\n",
    "\n",
    "total_hc = len(K_range_hc) * len(epsilon_values)\n",
    "with tqdm(total=total_hc, desc=\"Experimentos Hard-Core\") as pbar:\n",
    "    for K in K_range_hc:\n",
    "        for eps in epsilon_values:\n",
    "            result = run_hardcore_experiment(K, eps)\n",
    "            all_results_hc.append(result)\n",
    "            pbar.update(1)\n",
    "\n",
    "df_hc = pd.DataFrame(all_results_hc)\n",
    "print(f\"\\n{len(all_results_hc)} experimentos Hard-Core completados\")\n",
    "\n",
    "# Mostrar estadísticas\n",
    "print(\"\\n=== Resumen de parámetros Hard-Core ===\")\n",
    "for eps in epsilon_values:\n",
    "    df_eps_hc = df_hc[df_hc['epsilon'] == eps]\n",
    "    print(f\"\\nε = {eps}:\")\n",
    "    print(f\"  • Simulaciones promedio: {df_eps_hc['num_simulations'].mean():.0f}\")\n",
    "    print(f\"  • Tiempo de mezcla promedio: {df_eps_hc['mixing_time'].mean():.0f} pasos\")\n",
    "    print(f\"  • Partículas promedio: {df_eps_hc['avg_particles'].mean():.2f}\")\n",
    "    print(f\"  • Tiempo ejecución promedio: {df_eps_hc['elapsed_time'].mean():.2f} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de Resultados Hard-Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear visualizaciones para Hard-Core\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Estimaciones vs tamaño del lattice\n",
    "ax1 = axes[0, 0]\n",
    "for eps in epsilon_values:\n",
    "    df_eps_hc = df_hc[df_hc['epsilon'] == eps]\n",
    "    ax1.semilogy(df_eps_hc['K'], df_eps_hc['estimate'], \n",
    "                'o-', label=f'ε={eps}', markersize=8)\n",
    "ax1.set_xlabel('Tamaño del Lattice (K)')\n",
    "ax1.set_ylabel('log(Número de Configuraciones)')\n",
    "ax1.set_title('Crecimiento del Número de Configuraciones Hard-Core')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Número promedio de partículas\n",
    "ax2 = axes[0, 1]\n",
    "df_01_hc = df_hc[df_hc['epsilon'] == 0.1]\n",
    "ax2.plot(df_01_hc['K'], df_01_hc['avg_particles'], \n",
    "        'go-', linewidth=2, markersize=8)\n",
    "ax2.fill_between(df_01_hc['K'], \n",
    "                 df_01_hc['avg_particles'] - np.sqrt(df_01_hc['var_particles']),\n",
    "                 df_01_hc['avg_particles'] + np.sqrt(df_01_hc['var_particles']),\n",
    "                 alpha=0.3, color='green')\n",
    "ax2.set_xlabel('Tamaño del Lattice (K)')\n",
    "ax2.set_ylabel('Número Promedio de Partículas')\n",
    "ax2.set_title('Partículas Promedio en Configuraciones Hard-Core (ε=0.1)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Tiempo de ejecución\n",
    "ax3 = axes[1, 0]\n",
    "for eps in epsilon_values:\n",
    "    df_eps_hc = df_hc[df_hc['epsilon'] == eps]\n",
    "    ax3.plot(df_eps_hc['K'], df_eps_hc['elapsed_time'], \n",
    "            'o-', label=f'ε={eps}', markersize=8)\n",
    "ax3.set_xlabel('Tamaño del Lattice (K)')\n",
    "ax3.set_ylabel('Tiempo de Ejecución (segundos)')\n",
    "ax3.set_title('Tiempo de Cómputo para Hard-Core')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Densidad de partículas\n",
    "ax4 = axes[1, 1]\n",
    "df_01_hc['density'] = df_01_hc['avg_particles'] / df_01_hc['k_vertices']\n",
    "ax4.bar(df_01_hc['K'].astype(str), df_01_hc['density'], color='coral')\n",
    "ax4.set_xlabel('Tamaño del Lattice (K)')\n",
    "ax4.set_ylabel('Densidad (partículas/vértices)')\n",
    "ax4.set_title('Densidad de Partículas en Hard-Core (ε=0.1)')\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../resultados/hardcore_analisis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Gráficas guardadas en resultados/hardcore_analisis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación con Valores Exactos para Hard-Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Comparación Hard-Core con Conteo Exacto ===\")\n",
    "print(\"\\nComparando aproximaciones con valores exactos para lattices pequeños:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'K':^5} {'Exacto':^15} {'Aproximado':^15} {'Error (%)':^15}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "hc_comparison_results = []\n",
    "\n",
    "for K in [2, 3, 4, 5]:\n",
    "    try:\n",
    "        exact_hc = exact_hardcore_count(K)\n",
    "        \n",
    "        lattice = LatticeGraph(K)\n",
    "        approx_hc = HardCoreApproximation(lattice, epsilon=0.05)\n",
    "        estimate_hc, _ = approx_hc.approximate_count(verbose=False)\n",
    "        \n",
    "        error_hc = abs(estimate_hc - exact_hc) / exact_hc * 100 if exact_hc > 0 else 0\n",
    "        \n",
    "        print(f\"{K:^5} {exact_hc:^15,} {estimate_hc:^15.0f} {error_hc:^15.2f}\")\n",
    "        \n",
    "        hc_comparison_results.append({\n",
    "            'K': K,\n",
    "            'exact': exact_hc,\n",
    "            'approximate': estimate_hc,\n",
    "            'error_percent': error_hc\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"{K:^5} {'N/A':^15} {'N/A':^15} {'N/A':^15}\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "\n",
    "df_hc_comparison = pd.DataFrame(hc_comparison_results)\n",
    "if not df_hc_comparison.empty:\n",
    "    print(f\"\\nError promedio: {df_hc_comparison['error_percent'].mean():.2f}%\")\n",
    "    print(f\"Error máximo: {df_hc_comparison['error_percent'].max():.2f}%\")\n",
    "    print(f\"Error mínimo: {df_hc_comparison['error_percent'].min():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar todos los resultados en CSV\n",
    "import os\n",
    "os.makedirs('../resultados', exist_ok=True)\n",
    "\n",
    "df_q.to_csv('../resultados/q_coloraciones_resultados.csv', index=False)\n",
    "df_hc.to_csv('../resultados/hardcore_resultados.csv', index=False)\n",
    "\n",
    "if not df_comparison.empty:\n",
    "    df_comparison.to_csv('../resultados/q_coloraciones_comparacion.csv', index=False)\n",
    "\n",
    "if not df_hc_comparison.empty:\n",
    "    df_hc_comparison.to_csv('../resultados/hardcore_comparacion.csv', index=False)\n",
    "\n",
    "print(\"Resultados guardados en la carpeta 'resultados/'\")\n",
    "print(\"\\nArchivos generados:\")\n",
    "print(\"  • q_coloraciones_resultados.csv\")\n",
    "print(\"  • hardcore_resultados.csv\")\n",
    "print(\"  • q_coloraciones_comparacion.csv\")\n",
    "print(\"  • hardcore_comparacion.csv\")\n",
    "print(\"  • q_coloraciones_analisis.png\")\n",
    "print(\"  • hardcore_analisis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen y Conclusiones\n",
    "\n",
    "### Resultados Principales\n",
    "\n",
    "1. **q-Coloraciones:**\n",
    "   - Implementación exitosa del algoritmo basado en el Teorema 9.1\n",
    "   - La condición $q > 2d^*$ es crítica para la convergencia\n",
    "   - El tiempo de mezcla crece con $O(k \\log k)$ como predice la teoría\n",
    "\n",
    "2. **Modelo Hard-Core:**\n",
    "   - El número de configuraciones crece exponencialmente con el tamaño del lattice\n",
    "   - La densidad de partículas se estabiliza alrededor de 0.25-0.30 para lattices grandes\n",
    "   - El algoritmo es eficiente incluso para lattices de tamaño moderado\n",
    "\n",
    "3. **Precisión del Algoritmo:**\n",
    "   - Con $\\varepsilon = 0.1$, logramos errores típicamente menores al 20%\n",
    "   - Mayor precisión requiere significativamente más tiempo de cómputo\n",
    "   - Trade-off claro entre precisión y eficiencia computacional\n",
    "\n",
    "### Observaciones Técnicas\n",
    "\n",
    "- El número de simulaciones escala como $O(k^3/\\varepsilon^2)$\n",
    "- El tiempo de mezcla depende logarítmicamente de $q/(q-1)$\n",
    "- Para lattices grandes (K > 10), el tiempo de cómputo se vuelve significativo\n",
    "\n",
    "### Trabajo Futuro\n",
    "\n",
    "- Implementar técnicas de reducción de varianza\n",
    "- Explorar paralelización de las simulaciones\n",
    "- Extender a otros tipos de grafos más allá de lattices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cadenas-markov",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
